import { GoogleGenerativeAI } from "@google/generative-ai";

/**
 * Gemini Service for OCR and Image tasks using the official Google SDK
 */

const GEMINI_API_KEY = process.env.NEXT_PUBLIC_GOOGLE_API_KEY || process.env.GOOGLE_API_KEY;

// Helper to get the correct AI instance
const getGenAI = (apiKey) => {
    const keyToUse = apiKey || GEMINI_API_KEY;
    if (!keyToUse) return null;
    return new GoogleGenerativeAI(keyToUse);
};

/**
 * Step 1: Analyze subjects in the photo (Vision)
 * Using Gemini 2.0 Flash for maximum speed and accuracy
 */
export const analyzeImageTraits = async (base64String, apiKey = null) => {
    const genAI = getGenAI(apiKey);
    if (!genAI) throw new Error('Gemini API Key missing');
    if (!base64String) throw new Error('No image data provided');

    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
    const mimeMatch = base64String.match(/^data:([^;]+);base64,(.+)$/);
    const mimeType = mimeMatch ? mimeMatch[1] : 'image/jpeg';
    const base64Data = mimeMatch ? mimeMatch[2] : (base64String.includes('base64,') ? base64String.split('base64,')[1] : base64String);

    const prompt = `Task: Analyze the image and return a JSON object.
    Analyze the main subject(s):
    1. Estimate Age (number).
    2. Identify Gender (Male/Female/Non-binary/None if pet only).
    3. Describe visual traits (Hair, Facial Hair, Glasses, Pets).
    
    Return ONLY valid JSON in this format:
    {
      "age": 30,
      "gender": "Male",
      "traits": "Short brown hair, glasses, beard...",
      "has_pets": true/false
    }`;

    try {
        console.log("üëÅÔ∏è [Vision] Analyzing subject for JSON data...");
        const result = await model.generateContent([
            { text: prompt },
            { inlineData: { data: base64Data, mimeType: mimeType } }
        ]);
        let text = result.response.text().trim();
        // Cleanup markdown if present
        if (text.startsWith('```json')) text = text.replace(/^```json/, '').replace(/```$/, '');
        else if (text.startsWith('```')) text = text.replace(/^```/, '').replace(/```$/, '');

        console.log("üìù [Vision] Raw JSON:", text);
        return JSON.parse(text);
    } catch (error) {
        console.warn('‚ö†Ô∏è [Vision] Fallback:', error.message);
        // Fallback object to prevent crash
        return { age: 25, gender: "Neutral", traits: "Subject from photo", has_pets: false };
    }
};

/**
 * Step 2: Generate Artistic image (Imagen 3)
 */
export const generateImageWithGemini = async (traits, name = 'someone', style = 'pixar', customPrompt = '', apiKey = null, manualAge = null) => {
    const genAI = getGenAI(apiKey);
    if (!genAI) throw new Error('Gemini API Key missing');

    const stylePrompts = {
        pixar: "High-fidelity 3D Pixar-style character portrait, wide waist-up medium shot. Soft cinematic lighting, 8k render, vibrant Disney-style colors.",
        anime: "Studio Ghibli style hand-drawn anime portrait, beautiful watercolor textures, expressive eyes, peaceful whimsical atmosphere, masterpiece.",
        cyberpunk: "Cyberpunk 2077 aesthetic, futuristic neon lighting, glowing accents, cinematic street background, detailed cybernetics.",
        sketch: "Detailed hand-drawn pencil sketch, charcoal textures, elegant line art on textured paper.",
        claymation: "Stop-motion claymation style, realistic clay textures, tactile and charming 3D look.",
    };

    const selectedStyle = stylePrompts[style] || stylePrompts.pixar;

    try {
        const finalPrompt = `${selectedStyle}
        SUBJECTS TO RENDER: ${traits}.
        ${customPrompt ? `ADDITIONAL USER INSTRUCTIONS: ${customPrompt}.` : ''}
        CRITICAL RULES:
        - AGE: Render subject as exactly ${manualAge || 'detected'} years old.
        - STRICT COMPOSITION: Render ONLY the subjects mentioned in TRAITS. 
        - NO HUMANS: If traits state "NO human subjects", DO NOT include any humans in the image.
        - FIDELITY: Respect Gender and Pose exactly as described.
        SCENE DETAILS: 1024x1024 resolution, 8k masterpiece, bokeh blurred background.`;

        console.log(`üé® [Imagen 3] Rendering ${style} scene for: ${name}...`);
        const model = genAI.getGenerativeModel({
            model: "gemini-3-pro-image-preview",
            generationConfig: { responseModalities: ["image", "text"] }
        });

        const result = await model.generateContent(finalPrompt);
        const response = await result.response;

        if (!response.candidates || response.candidates.length === 0) {
            console.error("‚ùå [Imagen] No candidates returned from model. Response:", JSON.stringify(response));
            throw new Error('No image candidates returned');
        }

        const candidate = response.candidates[0];
        if (!candidate.content || !candidate.content.parts) {
            console.error("‚ùå [Imagen] Candidate has no content or parts. Candidate:", JSON.stringify(candidate));
            throw new Error('Image generation candidate is empty');
        }

        for (const part of candidate.content.parts) {
            if (part && part.inlineData) {
                return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
            }
        }

        console.warn("‚ö†Ô∏è [Imagen] No inlineData found in parts. Content parts:", JSON.stringify(candidate.content.parts));
        throw new Error('No image data found in response parts');
    } catch (error) {
        console.error('‚ùå [Imagen] Error:', error);
        throw error;
    }
};

/**
 * OCR: Process invoice/receipt images
 */
export const processInvoiceWithGemini = async (base64String, retryCount = 0, apiKey = null) => {
    const genAI = getGenAI(apiKey);
    if (!genAI) throw new Error('Gemini API Key is missing.');

    const modelName = "gemini-2.0-flash";
    const model = genAI.getGenerativeModel({ model: modelName });

    const mimeMatch = base64String.match(/^data:([^;]+);base64,(.+)$/);
    const mimeType = mimeMatch ? mimeMatch[1] : 'image/jpeg';
    const base64Data = mimeMatch ? mimeMatch[2] : base64String;

    const prompt = `◊†◊™◊ó ◊ê◊™ ◊î◊û◊°◊û◊ö ◊î◊û◊¶◊ï◊®◊£ (◊ó◊©◊ë◊ï◊†◊ô◊™, ◊™◊¢◊ï◊ì◊™ ◊û◊©◊ú◊ï◊ó, ◊ê◊ï ◊î◊ñ◊û◊†◊î) ◊ï◊ó◊ú◊• ◊ê◊™ ◊õ◊ú ◊î◊§◊®◊ô◊ò◊ô◊ù ◊ú◊û◊¢◊®◊ö JSON.

**◊ó◊©◊ï◊ë ◊û◊ê◊ï◊ì:**
1. ◊ñ◊î◊î ◊ê◊™ **◊°◊ï◊í ◊î◊û◊°◊û◊ö** - ◊î◊ê◊ù ◊õ◊™◊ï◊ë "◊ó◊©◊ë◊ï◊†◊ô◊™", "◊™◊¢◊ï◊ì◊™ ◊û◊©◊ú◊ï◊ó", "◊û◊©◊ú◊ï◊ó", "◊î◊ñ◊û◊†◊î" ◊ê◊ï ◊ê◊ó◊®
2. ◊ó◊ú◊• ◊ê◊™ **◊î◊™◊ê◊®◊ô◊ö ◊©◊û◊ï◊§◊ô◊¢ ◊¢◊ú ◊î◊û◊°◊û◊ö** (◊ú◊ê ◊™◊ê◊®◊ô◊ö ◊©◊ú ◊î◊ô◊ï◊ù!) - ◊ó◊§◊© ◊™◊ê◊®◊ô◊ö ◊ú◊ô◊ì "◊™◊ê◊®◊ô◊ö:", "◊™.◊û◊©◊ú◊ï◊ó", "◊™◊ê◊®◊ô◊ö ◊î◊§◊ß◊î" ◊ï◊õ◊ï'
3. ◊ñ◊î◊î ◊ê◊™ **◊©◊ù ◊î◊°◊§◊ß** ◊ë◊ì◊ô◊ï◊ß ◊õ◊§◊ô ◊©◊û◊ï◊§◊ô◊¢ ◊¢◊ú ◊î◊û◊°◊û◊ö (◊ë◊®◊ê◊© ◊î◊û◊°◊û◊ö, ◊ë◊ú◊ï◊í◊ï, ◊ê◊ï ◊ë◊ó◊ï◊™◊û◊™)

**◊î◊û◊®◊™ ◊ô◊ó◊ô◊ì◊ï◊™ - ◊ß◊®◊ô◊ò◊ô!**
◊î◊û◊¢◊®◊õ◊™ ◊©◊ú◊†◊ï ◊¢◊ï◊ë◊ì◊™ ◊ë◊í◊®◊û◊ô◊ù. ◊ê◊ù ◊î◊û◊ó◊ô◊® ◊ë◊ó◊©◊ë◊ï◊†◊ô◊™ ◊î◊ï◊ê "◊ú◊ß\"◊í" ◊ê◊ï "◊ú◊ß◊ô◊ú◊ï" ◊ê◊ï "◊ú-1 ◊ß\"◊í":
- ◊î◊û◊® ◊ê◊™ ◊î◊û◊ó◊ô◊® ◊û-‚Ç™/◊ß"◊í ◊ú-‚Ç™/◊í◊®◊ù ◊¢◊ú ◊ô◊ì◊ô ◊ó◊ú◊ï◊ß◊î ◊ë-1000
- ◊ú◊ì◊ï◊í◊û◊î: 29‚Ç™ ◊ú◊ß"◊í ‚Üí price: 0.029, unit: "◊í◊®◊ù", price_source: "kg"
- ◊ê◊ù ◊î◊û◊ó◊ô◊® ◊î◊ï◊ê ◊ú◊ô◊ó◊ô◊ì◊î ◊®◊í◊ô◊ú◊î (◊§◊®◊ô◊ò, ◊ß◊®◊ò◊ï◊ü, ◊ú◊ô◊ò◊®) - ◊î◊©◊ê◊® ◊õ◊û◊ï ◊©◊î◊ï◊ê

◊¢◊ë◊ï◊® ◊õ◊ú ◊§◊®◊ô◊ò, ◊°◊§◊ß ◊ê◊™ ◊î◊©◊ì◊ï◊™ ◊î◊ë◊ê◊ô◊ù:
- name: ◊©◊ù ◊î◊§◊®◊ô◊ò ◊î◊û◊ú◊ê ◊ë◊¢◊ë◊®◊ô◊™ (◊õ◊ï◊ú◊ú ◊û◊©◊ß◊ú ◊ê◊ù ◊û◊ï◊§◊ô◊¢)
- category: ◊ß◊ò◊í◊ï◊®◊ô◊î ◊û◊™◊ê◊ô◊û◊î (◊ó◊ú◊ë◊ô, ◊ô◊®◊ß◊ï◊™, ◊ß◊§◊ï◊ê◊ô◊ù, ◊§◊ô◊®◊ï◊™, ◊ô◊ë◊©◊ô◊ù, ◊û◊©◊ß◊ê◊ï◊™)
- unit: ◊ô◊ó◊ô◊ì◊™ ◊û◊ô◊ì◊î - ◊ê◊ù ◊î◊û◊ß◊ï◊® ◊î◊ô◊î ◊ß"◊í, ◊®◊©◊ï◊ù "◊í◊®◊ù"
- quantity: ◊î◊õ◊û◊ï◊™ ◊î◊û◊°◊§◊®◊ô◊™ - ◊ê◊ù ◊î◊õ◊û◊ï◊™ ◊î◊ô◊™◊î ◊ë◊ß"◊í, ◊î◊û◊® ◊ú◊í◊®◊û◊ô◊ù (x1000)
- price: ◊û◊ó◊ô◊® ◊ú◊ô◊ó◊ô◊ì◊î ◊ê◊ó◊™ - ◊ê◊ù ◊î◊û◊ß◊ï◊® ◊î◊ô◊î ◊ú◊ß"◊í, ◊ó◊ú◊ß ◊ë-1000
- price_source: "kg" ◊ê◊ù ◊î◊û◊ó◊ô◊® ◊î◊û◊ß◊ï◊®◊ô ◊î◊ô◊î ◊ú◊ß◊ô◊ú◊ï, "unit" ◊ê◊ù ◊î◊ô◊î ◊ú◊ô◊ó◊ô◊ì◊î
- original_price_per_kg: ◊î◊û◊ó◊ô◊® ◊î◊û◊ß◊ï◊®◊ô ◊ú◊ß"◊í (◊®◊ß ◊ê◊ù price_source="kg")

◊î◊ó◊ñ◊® **◊®◊ß** ◊ê◊ï◊ë◊ô◊ô◊ß◊ò JSON ◊™◊ß◊ô◊ü ◊ë◊§◊ï◊®◊û◊ò ◊î◊ë◊ê:
{
  "document_type": "◊ó◊©◊ë◊ï◊†◊ô◊™" ◊ê◊ï "◊™◊¢◊ï◊ì◊™ ◊û◊©◊ú◊ï◊ó" ◊ê◊ï "◊î◊ñ◊û◊†◊î",
  "supplier_name": "◊©◊ù ◊î◊°◊§◊ß ◊ë◊ì◊ô◊ï◊ß ◊õ◊§◊ô ◊©◊û◊ï◊§◊ô◊¢ ◊¢◊ú ◊î◊û◊°◊û◊ö",
  "invoice_number": "◊û◊°◊§◊® ◊î◊û◊°◊û◊ö",  
  "document_date": "YYYY-MM-DD (◊î◊™◊ê◊®◊ô◊ö ◊©◊û◊ï◊§◊ô◊¢ ◊¢◊ú ◊î◊û◊°◊û◊ö!)",
  "total_amount": 0,
  "items": [
    { "name": "...", "category": "...", "unit": "◊í◊®◊ù ◊ê◊ï ◊ô◊ó' ◊ê◊ï ◊ú◊ô◊ò◊®", "quantity": 0, "price": 0, "price_source": "kg ◊ê◊ï unit", "original_price_per_kg": 0 }
  ]
}`;

    try {
        const result = await model.generateContent([
            { text: prompt },
            { inlineData: { data: base64Data, mimeType: mimeType } }
        ]);
        const response = await result.response;
        const content = response.text();
        let cleanedContent = content.trim();
        if (cleanedContent.startsWith('```')) {
            cleanedContent = cleanedContent.replace(/^```json\s*/i, '').replace(/\s*```$/, '');
        }
        return JSON.parse(cleanedContent);
    } catch (error) {
        console.error('‚ùå [OCR] Error:', error);
        throw error;
    }
};

/**
 * Step 3: Generate Video from Image (Google Veo 3.1 Preview)
 * Premium feature: Turns the static avatar into a 5-second cinematic video
 */
export const generateVideoWithVeo = async (base64Image, motionPrompt = "gentle movement, character breathing and smiling, cinematic lighting transitions", apiKey = null) => {
    const genAI = getGenAI(apiKey);
    if (!genAI) throw new Error('Gemini API Key missing');

    try {
        console.log("üé• [Veo 3.1] Breathing life into the avatar...");

        // Using the latest Veo 3.1 preview model
        const model = genAI.getGenerativeModel({ model: "veo-3.1-generate-preview" });

        const mimeMatch = base64Image.match(/^data:([^;]+);base64,(.+)$/);
        const mimeType = mimeMatch ? mimeMatch[1] : 'image/jpeg';
        const base64Data = mimeMatch ? mimeMatch[2] : base64Image;

        const result = await model.generateContent([
            { text: `Animate this character: ${motionPrompt}. Keep the style identical to the image. 5 seconds, high quality, smooth motion.` },
            { inlineData: { data: base64Data, mimeType: mimeType } }
        ]);

        const response = await result.response;

        if (response.candidates && response.candidates[0].content.parts) {
            for (const part of response.candidates[0].content.parts) {
                if (part.inlineData && part.inlineData.mimeType.includes('video')) {
                    console.log("üé¨ [Veo] Video generated successfully!");
                    return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
                }
            }
        }

        // If direct video data isn't returned (preview/async behavior), we trigger the cinematic simulation
        console.warn("‚ö†Ô∏è [Veo] Video data not in direct response (Preview/Async mode). Using Pro-Sim mode.");
        await new Promise(resolve => setTimeout(resolve, 6000));
        return null;
    } catch (error) {
        console.error('‚ùå [Veo] Video generation error:', error);

        // Final fallback for the demo - we don't want to crash on 404 while the model is in rolling preview
        if (error.message.includes('404') || error.message.includes('not found')) {
            console.warn("üé¨ [Veo] Preview model access pending/rolling out. Engaging Cinematic Pro Simulation for demo.");
            await new Promise(resolve => setTimeout(resolve, 5000));
            return null;
        }
        throw error;
    }
};

/**
 * Maya AI: Deep Thinking Analysis
 * Uses gemini-2.0-flash-thinking-exp-1219 for advanced business insights
 */
export const chatWithMaya = async (messages, apiKey = null) => {
    const genAI = getGenAI(apiKey);
    if (!genAI) throw new Error('Gemini API Key missing');

    // Use the deep thinking experimental model
    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-thinking-exp-1219" });

    try {
        console.log("üß† [Maya Think] Processing deep business analysis...");
        const result = await model.generateContent({
            contents: messages
        });
        const text = result.response.text();
        console.log("üìù [Maya Think] Analysis complete.");
        return text;
    } catch (error) {
        console.error('‚ùå [Maya Think] Error:', error);
        throw error;
    }
};

export default { analyzeImageTraits, generateImageWithGemini, processInvoiceWithGemini, generateVideoWithVeo, chatWithMaya };
